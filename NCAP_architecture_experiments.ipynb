{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQcVPU3-cuo"
      },
      "source": [
        "#### Neccessary module imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzW3TkM2InIE"
      },
      "source": [
        "NCAP model GPU environment imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owf2SFK-IGAB"
      },
      "outputs": [],
      "source": [
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "print('Installing dm_control...')\n",
        "!pip install -q dm_control>=1.0.16\n",
        "\n",
        "# Configure dm_control to use the EGL rendering backend (requires GPU)\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")\n",
        "!pip install -q dm-acme[envs]\n",
        "!mkdir output_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTQ_qmXC-69O"
      },
      "outputs": [],
      "source": [
        "#@title Download and install tonic library for training agents\n",
        "\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "\n",
        "!git clone https://github.com/neuromatch/tonic\n",
        "%cd tonic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feiJQP2_-ayG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import argparse\n",
        "import os\n",
        "import yaml\n",
        "import typing as T\n",
        "import imageio\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn\n",
        "import dm_control as dm\n",
        "import dm_control.suite.swimmer as swimmer\n",
        "from dm_control.rl import control\n",
        "import logging\n",
        "from IPython.display import HTML\n",
        "from dm_control.utils import rewards\n",
        "from dm_control import suite\n",
        "from dm_control.suite.wrappers import pixels\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from acme import wrappers\n",
        "import plotly.graph_objs as go\n",
        "from torch import nn\n",
        "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ww9JZCTf-uR4"
      },
      "outputs": [],
      "source": [
        "#@title Utility code for displaying videos\n",
        "def write_video(\n",
        "  filepath: os.PathLike,\n",
        "  frames: T.Iterable[np.ndarray],\n",
        "  fps: int = 60,\n",
        "  macro_block_size: T.Optional[int] = None,\n",
        "  quality: int = 10,\n",
        "  verbose: bool = False,\n",
        "  **kwargs,\n",
        "):\n",
        "  \"\"\"\n",
        "  Saves a sequence of frames as a video file.\n",
        "\n",
        "  Parameters:\n",
        "  - filepath (os.PathLike): Path to save the video file.\n",
        "  - frames (Iterable[np.ndarray]): An iterable of frames, where each frame is a numpy array.\n",
        "  - fps (int, optional): Frames per second, defaults to 60.\n",
        "  - macro_block_size (Optional[int], optional): Macro block size for video encoding, can affect compression efficiency.\n",
        "  - quality (int, optional): Quality of the output video, higher values indicate better quality.\n",
        "  - verbose (bool, optional): If True, prints the file path where the video is saved.\n",
        "  - **kwargs: Additional keyword arguments passed to the imageio.get_writer function.\n",
        "\n",
        "  Returns:\n",
        "  None. The video is written to the specified filepath.\n",
        "  \"\"\"\n",
        "\n",
        "  with imageio.get_writer(filepath,\n",
        "                        fps=fps,\n",
        "                        macro_block_size=macro_block_size,\n",
        "                        quality=quality,\n",
        "                        **kwargs) as video:\n",
        "    if verbose: print('Saving video to:', filepath)\n",
        "    for frame in frames:\n",
        "      video.append_data(frame)\n",
        "\n",
        "\n",
        "def display_video(\n",
        "  frames: T.Iterable[np.ndarray],\n",
        "  filename='output_videos/temp.mp4',\n",
        "  fps=60,\n",
        "  **kwargs,\n",
        "):\n",
        "  \"\"\"\n",
        "  Displays a video within a Jupyter Notebook from an iterable of frames.\n",
        "\n",
        "  Parameters:\n",
        "  - frames (Iterable[np.ndarray]): An iterable of frames, where each frame is a numpy array.\n",
        "  - filename (str, optional): Temporary filename to save the video before display, defaults to 'output_videos/temp.mp4'.\n",
        "  - fps (int, optional): Frames per second for the video display, defaults to 60.\n",
        "  - **kwargs: Additional keyword arguments passed to the write_video function.\n",
        "\n",
        "  Returns:\n",
        "  HTML object: An HTML video element that can be displayed in a Jupyter Notebook.\n",
        "  \"\"\"\n",
        "\n",
        "  # Write video to a temporary file.\n",
        "  filepath = os.path.abspath(filename)\n",
        "  write_video(filepath, frames, fps=fps, verbose=False, **kwargs)\n",
        "\n",
        "  height, width, _ = frames[0].shape\n",
        "  dpi = 70\n",
        "  orig_backend = matplotlib.get_backend()\n",
        "  matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "  matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
        "  ax.set_axis_off()\n",
        "  ax.set_aspect('equal')\n",
        "  ax.set_position([0, 0, 1, 1])\n",
        "  im = ax.imshow(frames[0])\n",
        "  def update(frame):\n",
        "    im.set_data(frame)\n",
        "    return [im]\n",
        "  interval = 1000/fps\n",
        "  anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
        "                                  interval=interval, blit=True, repeat=False)\n",
        "  return HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQgLlUG_lhO"
      },
      "outputs": [],
      "source": [
        "def play_model(path, checkpoint='last',environment='default',seed=None, header=None):\n",
        "\n",
        "  \"\"\"\n",
        "    Plays a model within an environment and renders the gameplay to a video.\n",
        "\n",
        "    Parameters:\n",
        "    - path (str): Path to the directory containing the model and checkpoints.\n",
        "    - checkpoint (str): Specifies which checkpoint to use ('last', 'first', or a specific ID). 'none' indicates no checkpoint.\n",
        "    - environment (str): The environment to use. 'default' uses the environment specified in the configuration file.\n",
        "    - seed (int): Optional seed for reproducibility.\n",
        "    - header (str): Optional Python code to execute before initializing the model, such as importing libraries.\n",
        "    \"\"\"\n",
        "\n",
        "  if checkpoint == 'none':\n",
        "    # Use no checkpoint, the agent is freshly created.\n",
        "    checkpoint_path = None\n",
        "    tonic.logger.log('Not loading any weights')\n",
        "  else:\n",
        "    checkpoint_path = os.path.join(path, 'checkpoints')\n",
        "    if not os.path.isdir(checkpoint_path):\n",
        "      tonic.logger.error(f'{checkpoint_path} is not a directory')\n",
        "      checkpoint_path = None\n",
        "\n",
        "    # List all the checkpoints.\n",
        "    checkpoint_ids = []\n",
        "    for file in os.listdir(checkpoint_path):\n",
        "      if file[:5] == 'step_':\n",
        "        checkpoint_id = file.split('.')[0]\n",
        "        checkpoint_ids.append(int(checkpoint_id[5:]))\n",
        "\n",
        "    if checkpoint_ids:\n",
        "      if checkpoint == 'last':\n",
        "        # Use the last checkpoint.\n",
        "        checkpoint_id = max(checkpoint_ids)\n",
        "        checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n",
        "      elif checkpoint == 'first':\n",
        "        # Use the first checkpoint.\n",
        "        checkpoint_id = min(checkpoint_ids)\n",
        "        checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n",
        "      else:\n",
        "        # Use the specified checkpoint.\n",
        "        checkpoint_id = int(checkpoint)\n",
        "        if checkpoint_id in checkpoint_ids:\n",
        "          checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n",
        "        else:\n",
        "          tonic.logger.error(f'Checkpoint {checkpoint_id} not found in {checkpoint_path}')\n",
        "          checkpoint_path = None\n",
        "    else:\n",
        "      tonic.logger.error(f'No checkpoint found in {checkpoint_path}')\n",
        "      checkpoint_path = None\n",
        "\n",
        "  # Load the experiment configuration.\n",
        "  arguments_path = os.path.join(path, 'config.yaml')\n",
        "  with open(arguments_path, 'r') as config_file:\n",
        "    config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
        "  config = argparse.Namespace(**config)\n",
        "\n",
        "  # Run the header first, e.g. to load an ML framework.\n",
        "  try:\n",
        "    if config.header:\n",
        "      exec(config.header)\n",
        "    if header:\n",
        "      exec(header)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # Build the agent.\n",
        "  agent = eval(config.agent)\n",
        "\n",
        "  # Build the environment.\n",
        "  if environment == 'default':\n",
        "    environment  = tonic.environments.distribute(lambda: eval(config.environment))\n",
        "  else:\n",
        "    environment  = tonic.environments.distribute(lambda: eval(environment))\n",
        "  if seed is not None:\n",
        "    environment.seed(seed)\n",
        "\n",
        "  # Initialize the agent.\n",
        "  agent.initialize(\n",
        "    observation_space=environment.observation_space,\n",
        "    action_space=environment.action_space,\n",
        "    seed=seed,\n",
        "  )\n",
        "\n",
        "  # Load the weights of the agent form a checkpoint.\n",
        "  if checkpoint_path:\n",
        "    agent.load(checkpoint_path)\n",
        "\n",
        "  steps = 0\n",
        "  test_observations = environment.start()\n",
        "  frames = [environment.render('rgb_array',camera_id=0, width=640, height=480)[0]]\n",
        "  score, length = 0, 0\n",
        "\n",
        "  neural_activity_values_list = []\n",
        "\n",
        "  while True:\n",
        "      # Select an action.\n",
        "      actions = agent.test_step(test_observations, steps)\n",
        "      assert not np.isnan(actions.sum())\n",
        "      neural_activity_values = agent.model.actor.get_connections_log_values()\n",
        "      for neuron_activity in neural_activity_values:\n",
        "          timestep, activity_type, neuron, param_value = neuron_activity\n",
        "          neural_activity_values_list.append({\n",
        "              'timestep': timestep,\n",
        "              'activity': 1 if activity_type == 'exc' else -1,\n",
        "              'neuron': neuron,\n",
        "              'param_value': param_value,\n",
        "          })\n",
        "      # Take a step in the environment.\n",
        "      test_observations, infos = environment.step(actions)\n",
        "      frames.append(environment.render('rgb_array',camera_id=0, width=640, height=480)[0])\n",
        "      agent.test_update(**infos, steps=steps)\n",
        "\n",
        "      score += infos['rewards'][0]\n",
        "      length += 1\n",
        "\n",
        "      if infos['resets'][0]:\n",
        "          break\n",
        "  video_path = os.path.join(path, 'video.mp4')\n",
        "  print('Reward for the run: ', score)\n",
        "  return display_video(frames,video_path), neural_activity_values_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ41ZPEOPPYQ"
      },
      "outputs": [],
      "source": [
        "_SWIM_SPEED = 0.1\n",
        "\n",
        "@swimmer.SUITE.add()\n",
        "def swim(\n",
        "  n_links=6,\n",
        "  desired_speed=_SWIM_SPEED,\n",
        "  time_limit=swimmer._DEFAULT_TIME_LIMIT,\n",
        "  random=None,\n",
        "  environment_kwargs={},\n",
        "):\n",
        "  \"\"\"Returns the Swim task for a n-link swimmer.\"\"\"\n",
        "  model_string, assets = swimmer.get_model_and_assets(n_links)\n",
        "  physics = swimmer.Physics.from_xml_string(model_string, assets=assets)\n",
        "  task = Swim(desired_speed=desired_speed, random=random)\n",
        "  return control.Environment(\n",
        "    physics,\n",
        "    task,\n",
        "    time_limit=time_limit,\n",
        "    control_timestep=swimmer._CONTROL_TIMESTEP,\n",
        "    **environment_kwargs,\n",
        "  )\n",
        "\n",
        "\n",
        "class Swim(swimmer.Swimmer):\n",
        "  \"\"\"Task to swim forwards at the desired speed.\"\"\"\n",
        "  def __init__(self, desired_speed=_SWIM_SPEED, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self._desired_speed = desired_speed\n",
        "\n",
        "  def initialize_episode(self, physics):\n",
        "    super().initialize_episode(physics)\n",
        "    # Hide target by setting alpha to 0.\n",
        "    physics.named.model.mat_rgba['target', 'a'] = 0\n",
        "    physics.named.model.mat_rgba['target_default', 'a'] = 0\n",
        "    physics.named.model.mat_rgba['target_highlight', 'a'] = 0\n",
        "\n",
        "  def get_observation(self, physics):\n",
        "    \"\"\"Returns an observation of joint angles and body velocities.\"\"\"\n",
        "    obs = collections.OrderedDict()\n",
        "    obs['joints'] = physics.joints()\n",
        "    obs['body_velocities'] = physics.body_velocities()\n",
        "    return obs\n",
        "\n",
        "  def get_reward(self, physics):\n",
        "    \"\"\"Returns a smooth reward that is 0 when stopped or moving backwards, and rises linearly to 1\n",
        "    when moving forwards at the desired speed.\"\"\"\n",
        "    forward_velocity = -physics.named.data.sensordata['head_vel'][1]\n",
        "    return rewards.tolerance(\n",
        "      forward_velocity,\n",
        "      bounds=(self._desired_speed, float('inf')),\n",
        "      margin=self._desired_speed,\n",
        "      value_at_margin=0.,\n",
        "      sigmoid='linear',\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wxr94t_X05"
      },
      "source": [
        "#### Train function for the NCAP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcNcg9MK_BXi"
      },
      "outputs": [],
      "source": [
        "import tonic\n",
        "import tonic.torch\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def train(\n",
        "  header,\n",
        "  agent,\n",
        "  environment,\n",
        "  name = 'test',\n",
        "  trainer = 'tonic.Trainer()',\n",
        "  before_training = None,\n",
        "  after_training = None,\n",
        "  parallel = 1,\n",
        "  sequential = 1,\n",
        "  seed = 0\n",
        "):\n",
        "  \"\"\"\n",
        "  Some additional parameters:\n",
        "\n",
        "  - before_training: Python code to execute immediately before the training loop commences, suitable for setup actions needed after initialization but prior to training.\n",
        "  - after_training: Python code to run once the training loop concludes, ideal for teardown or analytical purposes.\n",
        "  - parallel: The count of environments to execute in parallel. Limited to 1 in a Colab notebook, but if additional resources are available, this number can be increased to expedite training.\n",
        "  - sequential: The number of sequential steps the environment runs before sending observations back to the agent. This setting is useful for temporal batching. It can be disregarded for this tutorial's purposes.\n",
        "  - seed: The experiment's random seed, guaranteeing the reproducibility of the training process.\n",
        "\n",
        "  \"\"\"\n",
        "  # Capture the arguments to save them, e.g. to play with the trained agent.\n",
        "  args = dict(locals())\n",
        "\n",
        "  # Run the header first, e.g. to load an ML framework.\n",
        "  if header:\n",
        "    exec(header)\n",
        "\n",
        "  # Build the train and test environments.\n",
        "  _environment = environment\n",
        "  environment = tonic.environments.distribute(lambda: eval(_environment), parallel, sequential)\n",
        "  test_environment = tonic.environments.distribute(lambda: eval(_environment))\n",
        "\n",
        "\n",
        "  # Build the agent.\n",
        "  agent = eval(agent)\n",
        "  agent.initialize(\n",
        "    observation_space=test_environment.observation_space,\n",
        "    action_space=test_environment.action_space, seed=seed)\n",
        "\n",
        "  # Choose a name for the experiment.\n",
        "  if hasattr(test_environment, 'name'):\n",
        "    environment_name = test_environment.name\n",
        "  else:\n",
        "    environment_name = test_environment.__class__.__name__\n",
        "  if not name:\n",
        "    if hasattr(agent, 'name'):\n",
        "      name = agent.name\n",
        "    else:\n",
        "      name = agent.__class__.__name__\n",
        "    if parallel != 1 or sequential != 1:\n",
        "      name += f'-{parallel}x{sequential}'\n",
        "\n",
        "  # add you drive path '/content/drive/My Drive/your_directory_name'\n",
        "  path = os.path.join('/content/drive/My Drive/', 'data', 'experiments', 'tonic', environment_name, name)\n",
        "  print (f\"path for saving logs/model --- {path}\")\n",
        "  tonic.logger.initialize(path, script_path=None, config=args)\n",
        "\n",
        "  # Build the trainer.\n",
        "  trainer = eval(trainer)\n",
        "  trainer.initialize(\n",
        "    agent=agent,\n",
        "    environment=environment,\n",
        "    test_environment=test_environment,\n",
        "  )\n",
        "  # Run some code before training.\n",
        "  if before_training:\n",
        "    exec(before_training)\n",
        "\n",
        "  # Train.\n",
        "  trainer.run()\n",
        "\n",
        "  # Run some code after training.\n",
        "  if after_training:\n",
        "    exec(after_training)\n",
        "\n",
        "  # save the connection logs\n",
        "  neural_activity_list = agent.model.actor.get_connections_log_values()\n",
        "\n",
        "  if neural_activity_list:\n",
        "    neural_activity_file_path = os.path.join(path, 'neural_activity.csv')\n",
        "    neural_activity_df = pd.DataFrame(neural_activity_list, columns=['timestep', 'activity_type', 'neuron', 'param_value'])\n",
        "    neural_activity_df.to_csv(neural_activity_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nntNhz__wys"
      },
      "source": [
        "### NCAP parameter initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MgFey9dCIPW"
      },
      "source": [
        "#### Weight initialization distribution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initalizing_type = \"he\"\n",
        "clamped = True"
      ],
      "metadata": {
        "id": "Z4DjQjSQaR8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZDD5h6U_fES"
      },
      "outputs": [],
      "source": [
        "# Weight constraints\n",
        "def excitatory(w, upper=None):\n",
        "    return w.clamp(min=0, max=upper)\n",
        "def inhibitory(w, lower=None):\n",
        "    return w.clamp(min=lower, max=0)\n",
        "def unsigned(w, lower=None, upper=None):\n",
        "    return w if lower is None and upper is None else w.clamp(min=lower, max=upper)\n",
        "\n",
        "# Activation constraints\n",
        "def graded(x):\n",
        "    return x.clamp(min=0, max=1)\n",
        "\n",
        "def initialize_weights(shape=(1,), init_type='uniform', lower=-1., upper=1., clamped=True, type=None):\n",
        "    if init_type == 'uniform':\n",
        "        param = nn.init.uniform_(nn.Parameter(torch.empty(shape)), a=lower, b=upper)\n",
        "    elif init_type == 'xavier':\n",
        "        if len(shape) < 2:\n",
        "            # add a dimension if missing\n",
        "            shape = (1, shape[0])\n",
        "        param = nn.init.xavier_uniform_(nn.Parameter(torch.empty(shape)))\n",
        "    elif init_type == 'he':\n",
        "        if len(shape) < 2:\n",
        "            # add a dimension if missing\n",
        "            shape = (1, shape[0])\n",
        "        param = nn.init.kaiming_uniform_(nn.Parameter(torch.empty(shape)), nonlinearity='relu')\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown initialization type: {init_type}\")\n",
        "\n",
        "    # clamp the values if needed\n",
        "    if clamped:\n",
        "        param.data.clamp_(min=lower, max=upper)\n",
        "\n",
        "    # apply the excitatory/inhibitory logic\n",
        "    if type == 'exc':\n",
        "        param.data = excitatory(param.data)\n",
        "    elif type == 'inh':\n",
        "        param.data = inhibitory(param.data)\n",
        "    return param\n",
        "\n",
        "# Weight initialization\n",
        "def excitatory_weights(clamped, shape=(1,), init_type='uniform', lower=0., upper=1.):\n",
        "    assert lower >= 0\n",
        "    return initialize_weights(shape, init_type, lower, upper, clamped, type='exc')\n",
        "\n",
        "def inhibitory_weights(clamped, shape=(1,), init_type='uniform', lower=-1., upper=0.):\n",
        "    assert upper <= 0\n",
        "    return initialize_weights(shape, init_type, lower, upper, clamped, type='inh')\n",
        "\n",
        "def unsigned_weights(clamped, shape=(1,), init_type='uniform', lower=-1., upper=1.):\n",
        "    return initialize_weights(shape, init_type, lower, upper, clamped)\n",
        "\n",
        "def excitatory_constant(shape=(1,), value=1.):\n",
        "    return nn.Parameter(torch.full(shape, value))\n",
        "\n",
        "def inhibitory_constant(shape=(1,), value=-1.):\n",
        "    return nn.Parameter(torch.full(shape, value))\n",
        "\n",
        "def unsigned_constant(shape=(1,), lower=-1., upper=1., p=0.5):\n",
        "    with torch.no_grad():\n",
        "        weight = torch.empty(shape).uniform_(0, 1)\n",
        "        mask = weight < p\n",
        "        weight[mask] = upper\n",
        "        weight[~mask] = lower\n",
        "        return nn.Parameter(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA74vzPNCHUD"
      },
      "outputs": [],
      "source": [
        "def plot_weights_init_distribution(weight_init_type: str = \"uniform\"):\n",
        "  # checking the distribution by taking 1000 samples\n",
        "  shape = (1000, 1)\n",
        "  # generate weights for each distribution\n",
        "  weights_excitatory = excitatory_weights(clamped=clamped, shape=shape, init_type=weight_init_type)\n",
        "  weights_inhibitory = inhibitory_weights(clamped=clamped, shape=shape, init_type=weight_init_type)\n",
        "  weights_unsigned = unsigned_weights(clamped=clamped, shape=shape, init_type=weight_init_type)\n",
        "\n",
        "  # convert torch tensors to numpy arrays for plotting\n",
        "  weights_excitatory_np = weights_excitatory.detach().numpy()\n",
        "  weights_inhibitory_np = weights_inhibitory.detach().numpy()\n",
        "  weights_unsigned_np = weights_unsigned.detach().numpy()\n",
        "\n",
        "  # Plotting the histograms\n",
        "  plt.figure(figsize=(18, 6))\n",
        "\n",
        "  # Excitatory uniform weights\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.hist(weights_excitatory_np, bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
        "  plt.title(f'Excitatory {weight_init_type} clamped {clamped} Weights')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Inhibitory uniform weights\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.hist(weights_inhibitory_np, bins=50, density=True, alpha=0.7, color='green', edgecolor='black')\n",
        "  plt.title(f'Inhibitory {weight_init_type} clamped {clamped} Weights')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Unsigned uniform weights\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.hist(weights_unsigned_np, bins=50, density=True, alpha=0.7, color='orange', edgecolor='black')\n",
        "  plt.title(f'Unsigned {weight_init_type} clamped {clamped} Weights')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.grid(True)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "plot_weights_init_distribution(weight_init_type=weight_initalizing_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuyquBc9egxs"
      },
      "outputs": [],
      "source": [
        "include_contra_forward_feedback_control = False\n",
        "inclue_self_feedback_inhibition = False\n",
        "# I expect the model to not do movement properly\n",
        "include_head_oscillators = True\n",
        "# set as False if testing with different wt initialization\n",
        "use_weight_constant_init = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joGpOqyzESDw"
      },
      "source": [
        "Define Swimmer Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv497i27Dqo7"
      },
      "outputs": [],
      "source": [
        "class SwimmerModule(nn.Module):\n",
        "    \"\"\"C.-elegans-inspired neural circuit architectural prior.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_joints: int,\n",
        "            log_dir: str,\n",
        "            log_file: str = None,\n",
        "            n_turn_joints: int = 1,\n",
        "            oscillator_period: int = 60,\n",
        "            use_weight_sharing: bool = True,\n",
        "            use_weight_constraints: bool = True,\n",
        "            use_weight_constant_init: bool = use_weight_constant_init,\n",
        "            include_proprioception: bool = True,\n",
        "            include_head_oscillators: bool = include_head_oscillators,\n",
        "            include_speed_control: bool = False,\n",
        "            include_turn_control: bool = False,\n",
        "            include_contra_feedback_control: bool = include_contra_forward_feedback_control,\n",
        "            include_self_feedback_inh: bool = inclue_self_feedback_inhibition,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.n_joints = n_joints\n",
        "        self.n_turn_joints = n_turn_joints\n",
        "        self.oscillator_period = oscillator_period\n",
        "        self.include_proprioception = include_proprioception\n",
        "        self.include_head_oscillators = include_head_oscillators\n",
        "        self.include_speed_control = include_speed_control\n",
        "        self.include_turn_control = include_turn_control\n",
        "        self.include_contra_feedback_control = include_contra_forward_feedback_control\n",
        "        self.include_self_feedback_inh = include_self_feedback_inh\n",
        "        self.log_file = log_file\n",
        "        self.log_dir = log_dir\n",
        "\n",
        "        # Log activity\n",
        "        self.connections_log = []\n",
        "\n",
        "        # Timestep counter (for oscillations).\n",
        "        self.timestep = 0\n",
        "\n",
        "        # Weight sharing switch function.\n",
        "        self.ws = lambda nonshared, shared: shared if use_weight_sharing else nonshared\n",
        "\n",
        "        # Weight constraint and init functions.\n",
        "        if use_weight_constraints:\n",
        "            self.exc = excitatory\n",
        "            self.inh = inhibitory\n",
        "            if use_weight_constant_init:\n",
        "                exc_param = excitatory_constant\n",
        "                inh_param = inhibitory_constant\n",
        "            else:\n",
        "                print(f'using wts from distribution {weight_initalizing_type} with range clamp {clamped}')\n",
        "                exc_param = excitatory_weights(init_type=weight_initalizing_type, clamped=clamped)\n",
        "                inh_param = inhibitory_weights(init_type=weight_initalizing_type, clamped=clamped)\n",
        "        else:\n",
        "            self.exc = unsigned\n",
        "            self.inh = unsigned\n",
        "            if use_weight_constant_init:\n",
        "                exc_param = inh_param = unsigned_constant\n",
        "            else:\n",
        "                exc_param = inh_param = unsigned_weights(init_type=weight_initalizing_type)\n",
        "\n",
        "        # Learnable parameters.\n",
        "        self.params = nn.ParameterDict()\n",
        "        if use_weight_sharing:\n",
        "            if self.include_proprioception:\n",
        "                self.params['bneuron_prop'] = exc_param() if use_weight_constant_init else nn.Parameter(exc_param.data.clone())\n",
        "            if self.include_speed_control:\n",
        "                self.params['bneuron_speed'] = inh_param() if use_weight_constant_init else nn.Parameter(inh_param.data.clone())\n",
        "            if self.include_turn_control:\n",
        "                self.params['bneuron_turn'] = exc_param() if use_weight_constant_init else nn.Parameter(exc_param.data.clone())\n",
        "            if self.include_head_oscillators:\n",
        "                self.params['bneuron_osc'] = exc_param() if use_weight_constant_init else nn.Parameter(exc_param.data.clone())\n",
        "            if self.include_self_feedback_inh:\n",
        "                self.params['D_sfeedback'] = inh_param() if use_weight_constant_init else nn.Parameter(inh_param.data.clone())\n",
        "            self.params['muscle_ipsi'] = exc_param() if use_weight_constant_init else nn.Parameter(exc_param.data.clone())\n",
        "            self.params['muscle_contra'] = inh_param() if use_weight_constant_init else nn.Parameter(inh_param.data.clone())\n",
        "        else:\n",
        "            for i in range(self.n_joints):\n",
        "                if self.include_proprioception and i > 0:\n",
        "                    self.params[f'bneuron_d_prop_{i}'] = exc_param()\n",
        "                    self.params[f'bneuron_v_prop_{i}'] = exc_param()\n",
        "\n",
        "                if self.include_self_feedback_inh and i > 0:\n",
        "                    self.params[f'D_d_sfeedback_{i}'] = inh_param()\n",
        "                    self.params[f'D_v_sfeedback_{i}'] = inh_param()\n",
        "\n",
        "                if self.include_speed_control:\n",
        "                    self.params[f'bneuron_d_speed_{i}'] = inh_param()\n",
        "                    self.params[f'bneuron_v_speed_{i}'] = inh_param()\n",
        "\n",
        "                if self.include_turn_control and i < self.n_turn_joints:\n",
        "                    self.params[f'bneuron_d_turn_{i}'] = exc_param()\n",
        "                    self.params[f'bneuron_v_turn_{i}'] = exc_param()\n",
        "\n",
        "                if self.include_head_oscillators and i == 0:\n",
        "                    self.params[f'bneuron_d_osc_{i}'] = exc_param()\n",
        "                    self.params[f'bneuron_v_osc_{i}'] = exc_param()\n",
        "\n",
        "                self.params[f'muscle_d_d_{i}'] = exc_param()\n",
        "                self.params[f'muscle_d_v_{i}'] = inh_param()\n",
        "                self.params[f'muscle_v_v_{i}'] = exc_param()\n",
        "                self.params[f'muscle_v_d_{i}'] = inh_param()\n",
        "\n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "\n",
        "    def log_activity(self, activity_type, neuron, param_value):\n",
        "      \"\"\"Logs an active connection between neurons.\"\"\"\n",
        "      self.connections_log.append((self.timestep, activity_type, neuron, param_value))\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            joint_pos,\n",
        "            right_control=None,\n",
        "            left_control=None,\n",
        "            speed_control=None,\n",
        "            timesteps=None,\n",
        "            log_activity=True,\n",
        "    ):\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "    Args:\n",
        "      joint_pos (torch.Tensor): Joint positions in [-1, 1], shape (..., n_joints).\n",
        "      right_control (torch.Tensor): Right turn control in [0, 1], shape (..., 1).\n",
        "      left_control (torch.Tensor): Left turn control in [0, 1], shape (..., 1).\n",
        "      speed_control (torch.Tensor): Speed control in [0, 1], 0 stopped, 1 fastest, shape (..., 1).\n",
        "      timesteps (torch.Tensor): Timesteps in [0, max_env_steps], shape (..., 1).\n",
        "\n",
        "    Returns:\n",
        "      (torch.Tensor): Joint torques in [-1, 1], shape (..., n_joints).\n",
        "    \"\"\"\n",
        "\n",
        "        exc = self.exc\n",
        "        inh = self.inh\n",
        "        ws = self.ws\n",
        "\n",
        "\n",
        "        # Separate into dorsal and ventral sensor values in [0, 1], shape (..., n_joints).\n",
        "        joint_pos_d = joint_pos.clamp(min=0, max=1)\n",
        "        joint_pos_v = joint_pos.clamp(min=-1, max=0).neg()\n",
        "\n",
        "        # Convert speed signal from acceleration into brake.\n",
        "        if self.include_speed_control:\n",
        "            assert speed_control is not None\n",
        "            speed_control = 1 - speed_control.clamp(min=0, max=1)\n",
        "\n",
        "        joint_torques = []  # [shape (..., 1)]\n",
        "        for i in range(self.n_joints):\n",
        "            bneuron_d = bneuron_v = torch.zeros_like(joint_pos[..., 0, None])  # shape (..., 1)\n",
        "            D_d = D_v = torch.zeros_like(joint_pos[..., 0, None])  # shape (..., 1)\n",
        "\n",
        "            # B-neurons recieve proprioceptive input from previous joint to propagate waves down the body.\n",
        "            if self.include_proprioception and i > 0:\n",
        "                bneuron_d = bneuron_d + joint_pos_d[\n",
        "                    ..., i - 1, None] * exc(self.params[ws(f'bneuron_d_prop_{i}', 'bneuron_prop')])\n",
        "                bneuron_v = bneuron_v + joint_pos_v[\n",
        "                    ..., i - 1, None] * exc(self.params[ws(f'bneuron_v_prop_{i}', 'bneuron_prop')])\n",
        "\n",
        "                self.log_activity('exc', f'bneuron_d_prop_{i}', self.params['bneuron_prop'].item())\n",
        "                self.log_activity('exc', f'bneuron_v_prop_{i}', self.params['bneuron_prop'].item())\n",
        "\n",
        "                # adding in the new variables for contra muscles for dorsal and ventral\n",
        "                if self.include_contra_feedback_control:\n",
        "                    contra_feedback = bneuron_d + bneuron_v\n",
        "\n",
        "            # B-neurons receive self inhibi\n",
        "            if self.include_self_feedback_inh:\n",
        "                D_d = bneuron_d + D_d + joint_pos_d[..., i - 1, None] * inh(self.params[ws(f'D_d_sfeedback_{i}', 'D_sfeedback')])\n",
        "                D_v = bneuron_v + D_v + joint_pos_v[..., i - 1, None] * inh(self.params[ws(f'D_v_sfeedback_{i}', 'D_sfeedback')])\n",
        "\n",
        "                self.log_activity('inh', f'D_d_sfeedback_{i}', self.params['D_sfeedback'].item())\n",
        "                self.log_activity('inh', f'D_v_sfeedback_{i}', self.params['D_sfeedback'].item())\n",
        "\n",
        "            # Speed control unit modulates all B-neurons.\n",
        "            if self.include_speed_control:\n",
        "                bneuron_d = bneuron_d + speed_control * inh(\n",
        "                    self.params[ws(f'bneuron_d_speed_{i}', 'bneuron_speed')]\n",
        "                )\n",
        "                bneuron_v = bneuron_v + speed_control * inh(\n",
        "                    self.params[ws(f'bneuron_v_speed_{i}', 'bneuron_speed')]\n",
        "                )\n",
        "\n",
        "                self.log_activity('inh', f'bneuron_d_speed_{i}', self.params['bneuron_speed'].item())\n",
        "                self.log_activity('inh', f'bneuron_v_speed_{i}', self.params['bneuron_speed'].item())\n",
        "\n",
        "            # Turn control units modulate head B-neurons.\n",
        "            if self.include_turn_control and i < self.n_turn_joints:\n",
        "                assert right_control is not None\n",
        "                assert left_control is not None\n",
        "                turn_control_d = right_control.clamp(min=0, max=1)  # shape (..., 1)\n",
        "                turn_control_v = left_control.clamp(min=0, max=1)\n",
        "                bneuron_d = bneuron_d + turn_control_d * exc(\n",
        "                    self.params[ws(f'bneuron_d_turn_{i}', 'bneuron_turn')]\n",
        "                )\n",
        "                bneuron_v = bneuron_v + turn_control_v * exc(\n",
        "                    self.params[ws(f'bneuron_v_turn_{i}', 'bneuron_turn')]\n",
        "                )\n",
        "\n",
        "                self.log_activity('exc', f'bneuron_d_turn_{i}', self.params['bneuron_turn'].item())\n",
        "                self.log_activity('exc', f'bneuron_v_turn_{i}', self.params['bneuron_turn'].item())\n",
        "\n",
        "            # Oscillator units modulate first B-neurons.\n",
        "            if self.include_head_oscillators and i == 0:\n",
        "                if timesteps is not None:\n",
        "                    phase = timesteps.round().remainder(self.oscillator_period)\n",
        "                    mask = phase < self.oscillator_period // 2\n",
        "                    oscillator_d = torch.zeros_like(timesteps)  # shape (..., 1)\n",
        "                    oscillator_v = torch.zeros_like(timesteps)  # shape (..., 1)\n",
        "                    oscillator_d[mask] = 1.\n",
        "                    oscillator_v[~mask] = 1.\n",
        "                else:\n",
        "                    phase = self.timestep % self.oscillator_period  # in [0, oscillator_period)\n",
        "                    if phase < self.oscillator_period // 2:\n",
        "                        oscillator_d, oscillator_v = 1.0, 0.0\n",
        "                    else:\n",
        "                        oscillator_d, oscillator_v = 0.0, 1.0\n",
        "                bneuron_d = bneuron_d + oscillator_d * exc(\n",
        "                    self.params[ws(f'bneuron_d_osc_{i}', 'bneuron_osc')]\n",
        "                )\n",
        "                bneuron_v = bneuron_v + oscillator_v * exc(\n",
        "                    self.params[ws(f'bneuron_v_osc_{i}', 'bneuron_osc')]\n",
        "                )\n",
        "                self.log_activity('exc', f'bneuron_d_osc_{i}', self.params['bneuron_osc'].item())\n",
        "                self.log_activity('exc', f'bneuron_v_osc_{i}', self.params['bneuron_osc'].item())\n",
        "\n",
        "            # B-neuron activation.\n",
        "            bneuron_d = graded(bneuron_d)\n",
        "            bneuron_v = graded(bneuron_v)\n",
        "\n",
        "            if self.include_contra_feedback_control:\n",
        "                contra_feedback = graded(contra_feedback)\n",
        "\n",
        "            if self.include_self_feedback_inh:\n",
        "                # D_d and D_v activation\n",
        "                D_d = graded(D_d)\n",
        "                D_v = graded(D_v)\n",
        "\n",
        "            # Muscles receive excitatory ipsilateral and inhibitory contralateral input.\n",
        "            if self.include_contra_feedback_control and not self.include_self_feedback_inh:\n",
        "                muscle_d = graded(bneuron_d * exc(self.params[ws(f'muscle_d_d_{i}', 'muscle_ipsi')]) + contra_feedback * inh(self.params[ws(f'muscle_d_v_{i}', 'muscle_contra')]))\n",
        "                muscle_v = graded(bneuron_v * exc(self.params[ws(f'muscle_v_v_{i}', 'muscle_ipsi')]) + contra_feedback * inh(self.params[ws(f'muscle_v_d_{i}', 'muscle_contra')]))\n",
        "            elif self.include_contra_feedback_control and self.include_self_feedback_inh:\n",
        "                muscle_d = graded(D_d * exc(self.params[ws(f'muscle_d_d_{i}', 'muscle_ipsi')]) + contra_feedback * inh(self.params[ws(f'muscle_d_v_{i}', 'muscle_contra')]))\n",
        "                muscle_v = graded(D_v * exc(self.params[ws(f'muscle_v_v_{i}', 'muscle_ipsi')]) + contra_feedback * inh(self.params[ws(f'muscle_v_d_{i}', 'muscle_contra')]))\n",
        "            else:\n",
        "                muscle_d = graded(\n",
        "                    bneuron_d * exc(self.params[ws(f'muscle_d_d_{i}', 'muscle_ipsi')]) +\n",
        "                    bneuron_v * inh(self.params[ws(f'muscle_d_v_{i}', 'muscle_contra')])\n",
        "                )\n",
        "                muscle_v = graded(\n",
        "                    bneuron_v * exc(self.params[ws(f'muscle_v_v_{i}', 'muscle_ipsi')]) +\n",
        "                    bneuron_d * inh(self.params[ws(f'muscle_v_d_{i}', 'muscle_contra')])\n",
        "                )\n",
        "            self.log_activity('exc', f'muscle_d_d_{i}', self.params['muscle_ipsi'].item())\n",
        "            self.log_activity('exc', f'muscle_v_v_{i}', self.params['muscle_ipsi'].item())\n",
        "            self.log_activity('inh', f'muscle_d_v_{i}', self.params['muscle_contra'].item())\n",
        "            self.log_activity('inh', f'muscle_v_d_{i}', self.params['muscle_contra'].item())\n",
        "\n",
        "            # Joint torque from antagonistic contraction of dorsal and ventral muscles.\n",
        "            joint_torque = muscle_d - muscle_v\n",
        "            joint_torques.append(joint_torque)\n",
        "\n",
        "        self.timestep += 1\n",
        "\n",
        "        out = torch.cat(joint_torques, -1)  # shape (..., n_joints)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE3j-gPmM21Z"
      },
      "source": [
        "Swimmer actor Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trying simple to control speed and turn, instead of some model\n",
        "def simple_controller(observations):\n",
        "    # Implement your logic to generate control signals\n",
        "    right = observations[:, 0] * 0.1\n",
        "    left = observations[:, 1] * 0.1\n",
        "    speed = observations[:, 2] * 0.1\n",
        "    return right, left, speed"
      ],
      "metadata": {
        "id": "VeBFCDE0Pu8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_UuKxt7M4od"
      },
      "outputs": [],
      "source": [
        "class SwimmerActor(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            swimmer,\n",
        "            controller=None,\n",
        "            distribution=None,\n",
        "            timestep_transform=(-1, 1, 0, 1000),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.swimmer = swimmer\n",
        "        self.controller = controller\n",
        "        self.distribution = distribution\n",
        "        self.timestep_transform = timestep_transform\n",
        "\n",
        "    def initialize(\n",
        "            self,\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            observation_normalizer=None,\n",
        "    ):\n",
        "        self.action_size = action_space.shape[0]\n",
        "\n",
        "    def get_connections_log_values(self):\n",
        "      return self.swimmer.connections_log\n",
        "\n",
        "    def forward(self, observations):\n",
        "        joint_pos = observations[..., :self.action_size]\n",
        "        timesteps = observations[..., -1, None]\n",
        "\n",
        "        # Normalize joint positions by max joint angle (in radians).\n",
        "        joint_limit = 2 * np.pi / (self.action_size + 1)  # In dm_control, calculated with n_bodies.\n",
        "        joint_pos = torch.clamp(joint_pos / joint_limit, min=-1, max=1)\n",
        "\n",
        "        # Convert normalized time signal into timestep.\n",
        "        if self.timestep_transform:\n",
        "            low_in, high_in, low_out, high_out = self.timestep_transform\n",
        "            timesteps = (timesteps - low_in) / (high_in - low_in) * (high_out - low_out) + low_out\n",
        "\n",
        "        # Generate high-level control signals.\n",
        "        if self.controller:\n",
        "            right, left, speed = simple_controller(observations)\n",
        "        else:\n",
        "            right, left, speed = None, None, None\n",
        "\n",
        "        # Generate low-level action signals.\n",
        "        actions = self.swimmer(\n",
        "            joint_pos,\n",
        "            timesteps=timesteps,\n",
        "            right_control=right,\n",
        "            left_control=left,\n",
        "            speed_control=speed,\n",
        "        )\n",
        "        # Pass through distribution for stochastic policy.\n",
        "        if self.distribution:\n",
        "            actions = self.distribution(actions)\n",
        "\n",
        "        return actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Ho6VXVM_5a"
      },
      "source": [
        "Train function for PPO and DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7JlbXmPNDki"
      },
      "outputs": [],
      "source": [
        "from tonic.torch import models, normalizers\n",
        "\n",
        "def ppo_swimmer_model(\n",
        "        activity_dir_file_path: str,\n",
        "        n_joints=5,\n",
        "        action_noise=0.1,\n",
        "        critic_sizes=(64, 64),\n",
        "        critic_activation=nn.Tanh,\n",
        "        **swimmer_kwargs,\n",
        "):\n",
        "    return models.ActorCritic(\n",
        "        actor=SwimmerActor(\n",
        "            swimmer=SwimmerModule(n_joints=n_joints, log_dir=activity_dir_file_path, **swimmer_kwargs),\n",
        "            distribution=lambda x: torch.distributions.normal.Normal(x, action_noise),\n",
        "        ),\n",
        "        critic=models.Critic(\n",
        "            encoder=models.ObservationEncoder(),\n",
        "            torso=models.MLP(critic_sizes, critic_activation),\n",
        "            head=models.ValueHead(),\n",
        "        ),\n",
        "        observation_normalizer=normalizers.MeanStd(),\n",
        "    )\n",
        "\n",
        "\n",
        "def d4pg_swimmer_model(\n",
        "  activity_dir_file_path: str,\n",
        "  n_joints=5,\n",
        "  critic_sizes=(256, 256),\n",
        "  critic_activation=nn.ReLU,\n",
        "  **swimmer_kwargs,\n",
        "):\n",
        "  # NOTE: swimmer kwargs empty -- what modifications/params can be used.\n",
        "  return models.ActorCriticWithTargets(\n",
        "    actor=SwimmerActor(swimmer=SwimmerModule(n_joints=n_joints, log_dir=activity_dir_file_path, **swimmer_kwargs),),\n",
        "    critic=models.Critic(\n",
        "      encoder=models.ObservationActionEncoder(),\n",
        "      torso=models.MLP(critic_sizes, critic_activation),\n",
        "      # These values are for the control suite with 0.99 discount.\n",
        "      head=models.DistributionalValueHead(-150., 150., 51),\n",
        "    ),\n",
        "    observation_normalizer=normalizers.MeanStd(),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmL6rToLnpTV"
      },
      "outputs": [],
      "source": [
        "steps = '2e5'\n",
        "# set ppo or ddpg\n",
        "alogrithm = 'ddpg'\n",
        "experiment_name = f'ncap_{alogrithm}_{weight_initalizing_type}_weight_init_steps_{steps}'\n",
        "print(f'experiment name {experiment_name}')\n",
        "activity_dir_file_path = os.path.join('/content/drive/My Drive/', 'data', 'experiments', 'tonic', \"swimmer-swim\", experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4mDvTRnN5-G"
      },
      "outputs": [],
      "source": [
        "train('import tonic.torch',\n",
        "      #'tonic.torch.agents.PPO(model=ppo_swimmer_model(n_joints=5, activity_dir_file_path=activity_dir_file_path, critic_sizes=(256,256)))',\n",
        "      'tonic.torch.agents.D4PG(model=d4pg_swimmer_model(n_joints=5, activity_dir_file_path=activity_dir_file_path, critic_sizes=(128,128)))',\n",
        "      'tonic.environments.ControlSuite(\"swimmer-swim\",time_feature=True)',\n",
        "      name = experiment_name,\n",
        "      trainer = 'tonic.Trainer(steps=int(2e5),save_steps=int(5e4))')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsghTF0yqurV"
      },
      "outputs": [],
      "source": [
        "model_results = play_model('/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_xavier_weight_init_steps_2e5_noclamp/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMy-fu7lCnNm"
      },
      "outputs": [],
      "source": [
        "# video\n",
        "model_results[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_he_weight_init_steps_2e5/'\n",
        "model_name = os.path.basename(path.rstrip('/'))\n",
        "df = pd.read_csv(os.path.join(path, 'neural_activity.csv'))\n",
        "df.columns = [\"timestep\", \"neuron_type\", \"neuron\", \"value\"]"
      ],
      "metadata": {
        "id": "QOdV-qiyivh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interval = 1000\n",
        "sampled_df = df[df['timestep'] % interval == 0]\n",
        "min_value = sampled_df['value'].min()\n",
        "max_value = sampled_df['value'].max()"
      ],
      "metadata": {
        "id": "hTmQ7t0bixac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sampled_df)"
      ],
      "metadata": {
        "id": "2eTIK6-ti0kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the animation\n",
        "fig = px.scatter(sampled_df, x=\"neuron\", y=\"value\", animation_frame=\"timestep\", color=\"neuron_type\", title=\"Neural Activity Over Time\")\n",
        "\n",
        "# Customize the layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Neuron\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend_title=\"Neuron Type\",\n",
        "    xaxis={'categoryorder':'total descending'},\n",
        "    yaxis=dict(range=[min_value, max_value])\n",
        ")\n",
        "\n",
        "# Save the figure as an HTML file\n",
        "html_file_path = os.path.join(path, 'neural_activity_animation.html')\n",
        "fig.write_html(html_file_path)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "rB0P9GjFi2iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUij7_2zDFom"
      },
      "outputs": [],
      "source": [
        "# from collections import defaultdict\n",
        "# # neural activities\n",
        "# # Create an animation of the neural activity bar plot\n",
        "# neural_activity_values_list = model_results[1]\n",
        "\n",
        "# # Extract unique neuron names\n",
        "# neuron_names = list({entry['neuron'] for entry in neural_activity_values_list})\n",
        "# neuron_indices = {name: idx for idx, name in enumerate(neuron_names)}\n",
        "# # Group entries by timestep\n",
        "# timesteps = defaultdict(list)\n",
        "# for entry in neural_activity_values_list:\n",
        "#     timesteps[entry['timestep']].append(entry)\n",
        "\n",
        "# # Sort timesteps for animation\n",
        "# sorted_timesteps = sorted(timesteps.keys())\n",
        "\n",
        "# # Initialize the plot\n",
        "# fig, ax = plt.subplots()\n",
        "# scatter = ax.scatter([], [], s=100)\n",
        "\n",
        "# # Set plot limits\n",
        "# ax.set_xlim(-0.5, len(neuron_names) - 0.5)\n",
        "# ax.set_ylim(-1.5, 1.5)\n",
        "# ax.set_xticks(range(len(neuron_names)))\n",
        "# ax.set_xticklabels(neuron_names, rotation=90)\n",
        "# ax.set_yticks([-1, 0, 1])\n",
        "# ax.set_ylabel('Activity')\n",
        "\n",
        "# # Update function for animation\n",
        "# def update(frame):\n",
        "#     timestep = sorted_timesteps[frame]\n",
        "#     x = [neuron_indices[entry['neuron']] for entry in timesteps[timestep]]\n",
        "#     y = [entry['activity'] for entry in timesteps[timestep]]\n",
        "\n",
        "#     scatter.set_offsets(list(zip(x, y)))\n",
        "#     ax.set_title(f'Timestep: {timestep}')\n",
        "\n",
        "# # Create animation\n",
        "# ani = FuncAnimation(fig, update, frames=len(sorted_timesteps), repeat=False)\n",
        "\n",
        "# # Display animation in Jupyter notebook\n",
        "# from IPython.display import HTML\n",
        "# HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHMpHW5ERmZI"
      },
      "source": [
        "Plotting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1vrqJ73RlxW"
      },
      "outputs": [],
      "source": [
        "def plot_performance(paths, title='Model Performance'):\n",
        "    \"\"\"\n",
        "    Plots the performance of multiple models on the same axes using Plotly for interactive visualization.\n",
        "\n",
        "    Reads CSV log files from specified paths and plots the mean episode scores\n",
        "    achieved during testing against the cumulative time steps for each model.\n",
        "    The plot uses a logarithmic scale for the x-axis to better display the progression\n",
        "    over a wide range of steps. Each line's legend is set to the name of the last folder\n",
        "    in the path, representing the model's name.\n",
        "\n",
        "    Parameters:\n",
        "    - paths (list of str): Paths to the experiment directories.\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for index, path in enumerate(paths):\n",
        "        # Extract the model name from the path\n",
        "        model_name = os.path.basename(path.rstrip('/'))\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(os.path.join(path, 'log.csv'))\n",
        "        scores = df['test/episode_score/mean']\n",
        "        lengths = df['test/episode_length/mean']\n",
        "        scores_min = df['test/episode_score/min']\n",
        "        scores_max = df['test/episode_score/max']\n",
        "        steps = np.cumsum(lengths)\n",
        "\n",
        "        # Add line plot for mean scores\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=steps, y=scores,\n",
        "            mode='lines',\n",
        "            name=f\"{model_name} mean\",\n",
        "            line=dict(color=f'rgba({index*50 % 255},{index*100 % 255},{index*150 % 255},1)')\n",
        "        ))\n",
        "\n",
        "        # Add shaded area for min and max scores\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=np.concatenate([steps, steps[::-1]]),\n",
        "            y=np.concatenate([scores_max, scores_min[::-1]]),\n",
        "            fill='toself',\n",
        "            fillcolor=f'rgba({index*50 % 255},{index*100 % 255},{index*150 % 255},0.2)',\n",
        "            line=dict(color='rgba(255,255,255,0)'),\n",
        "            hoverinfo=\"skip\",\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis=dict(title='Cumulative Time Steps', type='log', tickvals=[1e4, 1e5, 1e6], ticktext=['10^4', '10^5', '10^6']),\n",
        "        yaxis=dict(title='Episode Avg Score'),\n",
        "        legend_title='Models',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "def plot_actor_critic_loss(paths, title='Actor/Critic Loss'):\n",
        "    fig = go.Figure()\n",
        "    for index, path in enumerate(paths):\n",
        "        # Extract the model name from the path\n",
        "        model_name = os.path.basename(path.rstrip('/'))\n",
        "        # Load data\n",
        "        df = pd.read_csv(os.path.join(path, 'log.csv'))\n",
        "        actor_loss = df['actor/loss']\n",
        "        critic_loss = df['critic/loss']\n",
        "        lengths = df['test/episode_length/mean']\n",
        "        steps = np.cumsum(lengths)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=steps, y=actor_loss,\n",
        "            mode='lines',\n",
        "            name=f\"{model_name} actor loss\",\n",
        "            line=dict(color=f'rgba({index*50 % 255},{index*100 % 255},{index*150 % 255},1)')\n",
        "        ))\n",
        "\n",
        "        # Add line plot for critic loss\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=steps, y=critic_loss,\n",
        "            mode='lines',\n",
        "            name=f\"{model_name} critic loss\",\n",
        "            line=dict(dash='dash', color=f'rgba({(index+1)*50 % 255},{(index+1)*100 % 255},{(index+1)*150 % 255},0.5)')\n",
        "        ))\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis=dict(title='Cumulative Time Steps', type='log', tickvals=[1e4, 1e5, 1e6], ticktext=['10^4', '10^5', '10^6']),\n",
        "        yaxis=dict(title='Actor/Critic Loss'),\n",
        "        legend_title='Models',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "def plot_entropy_kl_divergence_actor_performance_PPO(model_path: str, title='Actor Entropy and KL Divergence'):\n",
        "    model_name = os.path.basename(model_path.rstrip('/'))\n",
        "    # Load data\n",
        "    df = pd.read_csv(os.path.join(model_path, 'log.csv'))\n",
        "    actor_entropy = df['actor/entropy']\n",
        "    actor_kl = df['actor/kl']\n",
        "    lengths = df['test/episode_length/mean']\n",
        "    steps = np.cumsum(lengths)\n",
        "\n",
        "    # Create traces\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=steps, y=actor_entropy,\n",
        "        mode='lines',\n",
        "        name=f\"{model_name} actor entropy\",\n",
        "        line=dict(color='blue')\n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=steps, y=actor_kl,\n",
        "        mode='lines',\n",
        "        name=f\"{model_name} actor kl divergence\",\n",
        "        line=dict(color='red')\n",
        "    ))\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis=dict(title='Cumulative Time Steps', type='log', tickvals=[1e4, 1e5, 1e6], ticktext=['10^4', '10^5', '10^6']),\n",
        "        yaxis=dict(title='Value'),\n",
        "        legend_title='Metrics',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_action_variance_DDPG(paths, title='Action Variance'):\n",
        "    fig = go.Figure()\n",
        "    colors = DEFAULT_PLOTLY_COLORS\n",
        "    for index, path in enumerate(paths):\n",
        "        model_name = os.path.basename(path.rstrip('/'))\n",
        "        df = pd.read_csv(os.path.join(path, 'log.csv'))\n",
        "        # Confirm it's for variance\n",
        "        action_variance = df['test/action/std']\n",
        "        lengths = df['test/episode_length/mean']\n",
        "        steps = np.cumsum(lengths)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=steps, y=action_variance,\n",
        "            mode='lines',\n",
        "            name=model_name,\n",
        "            line=dict(color=colors[index % len(colors)])\n",
        "        ))\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis=dict(title='Cumulative Time Steps', type='log', tickvals=[1e4, 1e5, 1e6], ticktext=['10^4', '10^5', '10^6']),\n",
        "        yaxis=dict(title='Action Variance'),\n",
        "        legend_title='Models',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "V4m8AIr5zr-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6HeIeF3fZgv"
      },
      "source": [
        "Comparions Models with respect to episode avg score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBC2b6Y8RthA"
      },
      "outputs": [],
      "source": [
        "basline_paths = [\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_osc_off/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_prop_off/',\n",
        "]\n",
        "plot_performance(basline_paths, title='Baseline NCAP models comparison with PPO and DDPG')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wt_init_paths = [\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_osc_off/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_prop_off/',\n",
        "]\n",
        "plot_performance(wt_init_paths, title='NCAP models comparison with movement parameters')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M4eI_EKA1FSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QLQK9RffgI1"
      },
      "source": [
        "Plot critic loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4HJTKvLR1R-"
      },
      "outputs": [],
      "source": [
        "loss_paths = [\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_baseline_ddpg_constant_weight_init_steps_2e5/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_uniform_weight_init_steps_2e5/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_he_weight_init_steps_2e5/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_xavier_weight_init_steps_2e5/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_he_weight_init_steps_2e5_noclamp/',\n",
        "]\n",
        "plot_actor_critic_loss(loss_paths, title=\"Actor/Critic Loss : Different Weight Initialization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jhh2KuSfldm"
      },
      "source": [
        "Entropy and KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyRGs7VfpIfJ"
      },
      "outputs": [],
      "source": [
        "#plot_entropy_kl_divergence_actor_performance_PPO('/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ppo_baseline_steps_6e5/', title='NCAP PPO')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9nyYWD2vTop"
      },
      "outputs": [],
      "source": [
        "action_vr_path = [\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_contra_feedback/',\n",
        "    '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_ddpg_constant_weight_init_steps_2e5_contra_feedback_self_inf/',\n",
        "]\n",
        "plot_action_variance_DDPG(paths=action_vr_path, title=\"Feedback : Action Variance Comparisons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmzECsn-_1ft"
      },
      "source": [
        "### Testing the visualization network [not working at the moment]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1u84tz4z2xN"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def draw_network(mode='NCAP', N=2, include_speed_control=False, include_turn_control=False, node_colors=None):\n",
        "    \"\"\"\n",
        "    Draws a network graph for a swimmer model based on either NCAP or MLP architecture.\n",
        "\n",
        "    Parameters:\n",
        "    - mode (str): Determines the architecture type ('NCAP' or 'MLP'). Defaults to 'NCAP'.\n",
        "    - N (int): Number of joints in the swimmer model. Defaults to 2.\n",
        "    - include_speed_control (bool): If True, includes nodes for speed control in the graph.\n",
        "    - include_turn_control (bool): If True, includes nodes for turn control in the graph.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    n=2+N*4\n",
        "\n",
        "    nodes =dict()\n",
        "\n",
        "    if include_speed_control:\n",
        "      nodes['1-s'] = n+7\n",
        "    if include_turn_control:\n",
        "      nodes['r'] = n+5\n",
        "      nodes['l'] = n+3\n",
        "\n",
        "    nodes['o'] = n-1\n",
        "    nodes['$o^d$'] = n-0\n",
        "    nodes['$o^v$']= n-2\n",
        "\n",
        "    custom_node_positions = {}\n",
        "    custom_node_positions['o'] = (1, nodes['o'])\n",
        "    custom_node_positions['$o^d$'] = (1.5, nodes['$o^d$'])\n",
        "    custom_node_positions['$o^v$'] = (1.5, nodes['$o^v$'])\n",
        "\n",
        "\n",
        "    if include_speed_control:\n",
        "      custom_node_positions['1-s'] = (1.5, nodes['1-s'])\n",
        "    if include_turn_control:\n",
        "      custom_node_positions['r'] = (1.5, nodes['r'])\n",
        "      custom_node_positions['l'] = (1.5, nodes['l'])\n",
        "\n",
        "    for i in range(1,N+1):\n",
        "      nodes[f'$q_{i}$'] = 4*(N-i) + 1\n",
        "      nodes[f'$q^d_{i}$'] = 4*(N-i) + 2\n",
        "      nodes[f'$q^v_{i}$'] = 4*(N-i)\n",
        "      nodes[f'$b^d_{i}$'] = 4*(N-i) + 2\n",
        "      nodes[f'$b^v_{i}$'] = 4*(N-i)\n",
        "      nodes[f'$m^d_{i}$'] = 4*(N-i) + 2\n",
        "      nodes[f'$m^v_{i}$'] = 4*(N-i)\n",
        "      nodes['$\\overset{..}{q}$' + f'$_{i}$'] = 4*(N-i) + 1\n",
        "\n",
        "      custom_node_positions[f'$q_{i}$'] = (1, nodes[f'$q_{i}$'])\n",
        "      custom_node_positions[f'$q^d_{i}$'] = (1.5, nodes[f'$q^d_{i}$'])\n",
        "      custom_node_positions[f'$q^v_{i}$'] = (1.5, nodes[f'$q^v_{i}$'])\n",
        "      custom_node_positions[f'$b^d_{i}$'] = (2, nodes[f'$b^d_{i}$'])\n",
        "      custom_node_positions[f'$b^v_{i}$'] = (2, nodes[f'$b^v_{i}$'])\n",
        "      custom_node_positions[f'$m^d_{i}$'] = (2.5, nodes[f'$m^d_{i}$'])\n",
        "      custom_node_positions[f'$m^v_{i}$'] = (2.5, nodes[f'$m^v_{i}$'])\n",
        "      custom_node_positions['$\\overset{..}{q}$' + f'$_{i}$'] = (3, nodes['$\\overset{..}{q}$' + f'$_{i}$'])\n",
        "\n",
        "    for node, layer in nodes.items():\n",
        "        G.add_node(node, layer=layer)\n",
        "\n",
        "    if mode=='NCAP':\n",
        "        # Add edges between nodes\n",
        "        edges_colors = ['green', 'orange', 'green', 'green']\n",
        "        edge_labels = {\n",
        "            ('o', '$o^d$'):'+1',\n",
        "            ('o', '$o^v$'):'-1',\n",
        "            ('$o^d$', '$b^d_1$'):'o',\n",
        "            ('$o^v$', '$b^v_1$'):'o'\n",
        "            }\n",
        "\n",
        "        if include_speed_control:\n",
        "          edges_colors += ['orange']\n",
        "          edge_labels[('1-s', '$b^d_1$')] = 's, to all b'\n",
        "        if include_turn_control:\n",
        "          edges_colors += ['green', 'green']\n",
        "          edge_labels[('r', '$b^d_1$')] = 't'\n",
        "          edge_labels[('l', '$b^v_1$')] = 't'\n",
        "\n",
        "\n",
        "        for i in range(1,N+1):\n",
        "          if i < N:\n",
        "            edges_colors += ['green', 'orange', 'green', 'green']\n",
        "\n",
        "            edge_labels[((f'$q_{i}$', f'$q^d_{i}$'))] = '+1'\n",
        "            edge_labels[((f'$q_{i}$', f'$q^v_{i}$'))] = '-1'\n",
        "            edge_labels[((f'$q^d_{i}$', f'$b^d_{i+1}$'))] = 'p'\n",
        "            edge_labels[((f'$q^v_{i}$', f'$b^v_{i+1}$'))] = 'p'\n",
        "\n",
        "          edges_colors += ['green', 'orange', 'green', 'orange',\n",
        "                          'orange', 'green']\n",
        "\n",
        "          edge_labels[((f'$b^d_{i}$', f'$m^d_{i}$'))] = 'i'\n",
        "          edge_labels[((f'$b^d_{i}$', f'$m^v_{i}$'))] = 'c'\n",
        "          edge_labels[((f'$b^v_{i}$', f'$m^v_{i}$'))] = 'i'\n",
        "          edge_labels[((f'$b^v_{i}$', f'$m^d_{i}$'))] = 'c'\n",
        "          edge_labels[((f'$m^v_{i}$', '$\\overset{..}{q}$' + f'$_{i}$'))] = '-1'\n",
        "          edge_labels[((f'$m^d_{i}$', '$\\overset{..}{q}$' + f'$_{i}$'))] = '+1'\n",
        "\n",
        "        edges = edge_labels.keys()\n",
        "    # G.add_edges_from(edges)\n",
        "\n",
        "    # # Draw the graph using the custom node positions\n",
        "    # options = {\"edge_color\": edges_colors, \"edgecolors\": \"tab:gray\", \"node_size\": 500, 'node_color':'white'}\n",
        "    # nx.draw(G, pos=custom_node_positions, with_labels=True, arrowstyle=\"-\", arrowsize=20, **options)\n",
        "    # nx.draw_networkx_edge_labels(G, pos=custom_node_positions, edge_labels=edge_labels)\n",
        "    # Get colors for nodes\n",
        "    color_map = []\n",
        "    for node in G.nodes():\n",
        "        if node_colors and node in node_colors:\n",
        "            color_map.append(node_colors[node])\n",
        "        else:\n",
        "            color_map.append('grey')  # default color\n",
        "\n",
        "    # Draw the graph\n",
        "    pos = custom_node_positions  # using the custom positions\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    nx.draw(G, pos, with_labels=True, node_color=color_map, node_size=7000, font_size=10, font_color='black', font_weight='bold', arrows=True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7re7djo80Va1"
      },
      "outputs": [],
      "source": [
        "# Map your neural activity data to the node names used in the graph\n",
        "neural_activity_logs_path = '/content/drive/My Drive/data/experiments/tonic/swimmer-swim/ncap_test_ppo_uniform_weight_init_steps_1e5_connection_logs/neural_activity.csv'\n",
        "df = pd.read_csv(neural_activity_logs_path)\n",
        "neural_activity_list = df.to_dict(orient='records')\n",
        "\n",
        "# node_colors = {}\n",
        "# for log in neural_activity_list:\n",
        "#   timestamp, activity_type, neuron = log\n",
        "#   if activity_type == 'exc':\n",
        "#       color = 'red'\n",
        "#   else:\n",
        "#       color = 'blue'\n",
        "#   if 'd_prop' in neuron:\n",
        "#       node_number = neuron.split('_')[-1]\n",
        "#       node_colors[f'$b^d_{node_number}$'] = color\n",
        "#   if 'v_prop' in neuron:\n",
        "#       node_number = neuron.split('_')[-1]\n",
        "#       node_colors[f'$b^v_{node_number}$'] = color\n",
        "\n",
        "breakpoint()\n",
        "#draw_network('NCAP', N=6, include_speed_control=True, include_turn_control=True, node_colors=node_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJAKHdhm0WF4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}